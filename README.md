# ğŸ¤– ATOS - Agentic Task Orchestrator with Standardized Tooling

> **A $0 multi-agent system that thinks, decomposes, and executes complex software projects using local LLMs**

![Project Status](https://img.shields.io/badge/status-in--development-yellow)
![Python](https://img.shields.io/badge/python-3.10+-blue)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ğŸ¯ What is ATOS?

ATOS is an **asynchronous multi-agent orchestration system** that takes a high-level goal (like "Build a price-tracking SaaS") and:

1. **Decomposes** it into concrete tasks (design, code, test, deploy)
2. **Routes** tasks to specialized AI agents based on complexity
3. **Executes** tasks in parallel when possible (simple tasks) or sequentially (complex tasks)
4. **Self-debugs** failed code using reflection loops
5. **Orchestrates** operations through custom n8n workflows

**The Innovation:** Instead of one large model doing everything, ATOS uses a **pool of small, specialized models** (1-7B parameters) that dynamically load/unload based on task requirements â€” making it runnable on consumer hardware (4GB VRAM).

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER INPUT: "Build a price-tracking SaaS"              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ORCHESTRATOR (Qwen2.5:7B - Always Loaded)            â”‚
â”‚  â€¢ Decomposes goal into tasks                         â”‚
â”‚  â€¢ Classifies: Simple | Medium | Complex              â”‚
â”‚  â€¢ Coordinates agent pools                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“ (sends task queue)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  n8n WORKFLOW ENGINE (Task Router)                     â”‚
â”‚  â€¢ In-memory task queue                                â”‚
â”‚  â€¢ Routes by complexity                                â”‚
â”‚  â€¢ Aggregates results                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                 â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT POOL Aâ”‚   â”‚ AGENT POOL Bâ”‚   â”‚ SPECIALIST CODER â”‚
â”‚ (Simple)    â”‚   â”‚ (Medium)    â”‚   â”‚ (Complex)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3x 1-3B     â”‚   â”‚ 1x 3-7B     â”‚   â”‚ 1x 7B Coder      â”‚
â”‚ models      â”‚   â”‚ model       â”‚   â”‚ model            â”‚
â”‚             â”‚   â”‚             â”‚   â”‚                  â”‚
â”‚ â€¢ File I/O  â”‚   â”‚ â€¢ API calls â”‚   â”‚ â€¢ Algorithms     â”‚
â”‚ â€¢ Parsing   â”‚   â”‚ â€¢ DB queriesâ”‚   â”‚ â€¢ Debug loops    â”‚
â”‚ â€¢ Configs   â”‚   â”‚ â€¢ Workflows â”‚   â”‚ â€¢ Full modules   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                 â†“                   â†“
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  RESULT AGGREGATOR   â”‚
              â”‚  (n8n node)          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  FINAL OUTPUT        â”‚
              â”‚  â€¢ Code repo         â”‚
              â”‚  â€¢ Deployment URL    â”‚
              â”‚  â€¢ Execution logs    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Why This Project Exists

**Learning Goals:**
- âœ… **Agentic Systems:** Build LLM-based agents with reasoning loops
- âœ… **Async Orchestration:** Coordinate multiple models working in parallel
- âœ… **VRAM Management:** Dynamically load/unload models on constrained hardware
- âœ… **MCP Protocol:** Design standardized tool interfaces
- âœ… **n8n Custom Nodes:** Extend workflow automation with TypeScript
- âœ… **Self-Debugging:** Implement reflection loops for code validation
- âœ… **Production Patterns:** Message queues, agent pools, observability

**This is NOT a toy project.** It's a production-grade architecture compressed to run on a laptop.

---

## ğŸ—‚ï¸ Repository Structure

```
atos/
â”œâ”€â”€ README.md                          # You are here
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ setup.py                          # Package setup
â”œâ”€â”€ .gitignore                        # Ignore models, logs, temp files
â”œâ”€â”€ .env.example                      # Environment variables template
â”‚
â”œâ”€â”€ docs/                             # Project documentation
â”‚   â”œâ”€â”€ architecture.md               # Deep dive into system design
â”‚   â”œâ”€â”€ model_selection.md            # Why these models were chosen
â”‚   â”œâ”€â”€ build_log.md                  # Daily build progress (your journal!)
â”‚   â””â”€â”€ troubleshooting.md            # Common errors and fixes
â”‚
â”œâ”€â”€ config/                           # Configuration files
â”‚   â”œâ”€â”€ models.yaml                   # Model definitions and VRAM limits
â”‚   â”œâ”€â”€ agents.yaml                   # Agent pool configurations
â”‚   â””â”€â”€ n8n_workflows.json            # n8n workflow exports
â”‚
â”œâ”€â”€ src/                              # Main source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                         # Core orchestration logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ orchestrator.py           # Main orchestrator (goal decomposer)
â”‚   â”‚   â”œâ”€â”€ task_classifier.py        # Classify tasks by complexity
â”‚   â”‚   â””â”€â”€ result_aggregator.py      # Combine agent outputs
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                       # Agent management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent_pool_manager.py     # Load/unload models, VRAM tracking
â”‚   â”‚   â”œâ”€â”€ agent_executor.py         # Execute tasks with specific agents
â”‚   â”‚   â””â”€â”€ models.py                 # Pydantic models for agents/tasks
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                        # MCP Tool Servers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ filesystem_server.py      # File read/write operations
â”‚   â”‚   â”œâ”€â”€ code_runner_server.py     # Execute pytest, return results
â”‚   â”‚   â””â”€â”€ workflow_server.py        # Trigger n8n workflows
â”‚   â”‚
â”‚   â”œâ”€â”€ langgraph/                    # LangGraph state machines
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ decompose_graph.py        # Goal â†’ Tasks state machine
â”‚   â”‚   â”œâ”€â”€ debug_loop_graph.py       # Self-debugging reflection loop
â”‚   â”‚   â””â”€â”€ states.py                 # State definitions (TypedDict)
â”‚   â”‚
â”‚   â”œâ”€â”€ n8n_integration/              # n8n communication
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ webhook_client.py         # Send tasks to n8n
â”‚   â”‚   â””â”€â”€ result_parser.py          # Parse n8n responses
â”‚   â”‚
â”‚   â””â”€â”€ observability/                # Logging and tracing
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ langsmith_tracer.py       # LangSmith integration
â”‚       â”œâ”€â”€ wandb_logger.py           # W&B metrics
â”‚       â””â”€â”€ logger.py                 # Standard Python logging
â”‚
â”œâ”€â”€ n8n/                              # n8n custom nodes (TypeScript)
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ ATOSAgentRouter/
â”‚   â”‚   â”‚   â”œâ”€â”€ ATOSAgentRouter.node.ts      # Routes tasks to agents
â”‚   â”‚   â”‚   â””â”€â”€ ATOSAgentRouter.node.json
â”‚   â”‚   â”œâ”€â”€ ATOSResultAggregator/
â”‚   â”‚   â”‚   â”œâ”€â”€ ATOSResultAggregator.node.ts
â”‚   â”‚   â”‚   â””â”€â”€ ATOSResultAggregator.node.json
â”‚   â”‚   â””â”€â”€ ATOSDeploy/
â”‚   â”‚       â”œâ”€â”€ ATOSDeploy.node.ts           # Deploy to platforms
â”‚   â”‚       â””â”€â”€ ATOSDeploy.node.json
â”‚   â””â”€â”€ credentials/
â”‚       â””â”€â”€ ATOSApi.credentials.ts
â”‚
â”œâ”€â”€ tests/                            # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_agent_pool.py
â”‚   â”‚   â”œâ”€â”€ test_orchestrator.py
â”‚   â”‚   â””â”€â”€ test_tools.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_full_workflow.py
â”‚   â”‚   â””â”€â”€ test_n8n_integration.py
â”‚   â””â”€â”€ fixtures/
â”‚       â””â”€â”€ sample_goals.json         # Test cases
â”‚
â”œâ”€â”€ examples/                         # Usage examples
â”‚   â”œâ”€â”€ 01_tracer_bullet.py          # Simplest end-to-end test
â”‚   â”œâ”€â”€ 02_single_agent.py           # One agent, one task
â”‚   â”œâ”€â”€ 03_agent_pool.py             # Multiple agents in parallel
â”‚   â””â”€â”€ 04_full_orchestration.py     # Complete ATOS workflow
â”‚
â”œâ”€â”€ scripts/                          # Utility scripts
â”‚   â”œâ”€â”€ setup_ollama.sh              # Pull all required models
â”‚   â”œâ”€â”€ check_vram.py                # Monitor GPU memory usage
â”‚   â”œâ”€â”€ test_n8n.sh                  # Verify n8n is running
â”‚   â””â”€â”€ cleanup.sh                   # Unload all models, clear cache
â”‚
â”œâ”€â”€ cli/                              # Command-line interface
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                      # CLI entry point
â”‚   â””â”€â”€ commands/
â”‚       â”œâ”€â”€ build.py                 # `atos build "goal"`
â”‚       â”œâ”€â”€ status.py                # `atos status`
â”‚       â””â”€â”€ debug.py                 # `atos debug <task_id>`
â”‚
â””â”€â”€ logs/                             # Runtime logs (not in git)
    â”œâ”€â”€ orchestrator.log
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ pool_a.log
    â”‚   â”œâ”€â”€ pool_b.log
    â”‚   â””â”€â”€ specialist.log
    â””â”€â”€ n8n/
        â””â”€â”€ workflows.log
```

---

## ğŸ§© Core Components Explained

### 1. **Orchestrator** (`src/core/orchestrator.py`)
**What it does:** The "director" that receives user goals and breaks them into tasks.

**Key responsibilities:**
- Parse user input ("Build a todo app")
- Use Qwen2.5:7B to decompose into specific tasks
- Classify each task as Simple/Medium/Complex
- Send task queue to n8n

**Models used:** Qwen2.5:7B-Instruct (always loaded, 4GB VRAM)

---

### 2. **Agent Pool Manager** (`src/agents/agent_pool_manager.py`)
**What it does:** The "VRAM traffic controller" that loads/unloads models.

**Key responsibilities:**
- Track available VRAM (4GB limit)
- Load appropriate agents for task type
- Execute tasks in parallel (simple) or sequential (complex)
- Unload models to free memory

**Challenge:** Your 4GB VRAM can't fit multiple 7B models simultaneously, so this component must intelligently swap them.

---

### 3. **MCP Tool Servers** (`src/tools/`)
**What they do:** Standardized APIs that agents call to perform operations.

**Tools:**
- `filesystem_server.py` - Read/write files (for generated code)
- `code_runner_server.py` - Execute pytest, return pass/fail
- `workflow_server.py` - Trigger n8n workflows (deployments, notifications)

**Why:** Agents shouldn't directly touch the filesystem or APIs â€” tools provide safe, logged interfaces.

---

### 4. **LangGraph State Machines** (`src/langgraph/`)
**What they do:** Define agent reasoning flows with loops.

**Graphs:**
- `decompose_graph.py` - Goal â†’ Task list
- `debug_loop_graph.py` - Code â†’ Test â†’ (if fail) Reflect â†’ Fix â†’ Test (repeat)

**Why LangGraph:** Because agents need to "think" in steps (Chain-of-Thought) and retry on failure.

---

### 5. **n8n Custom Nodes** (`n8n/nodes/`)
**What they do:** Extend n8n with ATOS-specific operations.

**Custom nodes:**
- `ATOSAgentRouter` - Receives tasks, routes to agent pools via API
- `ATOSResultAggregator` - Combines outputs from multiple agents
- `ATOSDeploy` - Deploys code to platforms (Heroku, GitHub Pages)

**Why custom nodes:** n8n's default nodes don't understand agent pools or VRAM management.

---

## ğŸš€ Quick Start

### Prerequisites
- **Python:** 3.10+
- **Node.js:** 18+
- **Ollama:** Installed and running
- **CUDA:** If using NVIDIA GPU (optional but recommended)
- **Storage:** 50GB free (for models)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/atos.git
cd atos

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install Python dependencies
pip install -r requirements.txt

# 4. Pull required models (will take 20-30 min)
bash scripts/setup_ollama.sh

# 5. Install n8n custom nodes
cd n8n
npm install
npm run build
npm link

# 6. Start n8n
npx n8n start

# 7. Copy environment variables
cp .env.example .env
# Edit .env with your settings
```

### First Test (Tracer Bullet)

```bash
# Run the simplest end-to-end test
python examples/01_tracer_bullet.py

# Expected output:
# ğŸ§  Loading orchestrator (Qwen2.5:7B)...
# âœ… Model loaded | VRAM: 4.1GB
# ğŸ¯ Goal: Write a Python function to add two numbers
# ğŸ“ Response: [model generates code]
# âœ… Tracer bullet complete!
```

If this works, your environment is ready! ğŸ‰

---

## ğŸ“ˆ Build Progress Tracker

Track your journey through the project phases:

### Phase 1: Foundation (Weeks 1-2) ğŸ”¨
- [ ] Repository structure created
- [ ] Ollama models pulled (6 models)
- [ ] Tracer bullet #1: Single model call works
- [ ] Tracer bullet #2: Task decomposition works
- [ ] Agent Pool Manager skeleton implemented
- [ ] VRAM tracking working (`nvidia-smi` integration)

### Phase 2: Agent Orchestration (Weeks 3-4) ğŸ¤–
- [ ] Agent pool loading/unloading works
- [ ] Simple task pool (3x small models) executes in parallel
- [ ] Medium task pool (1x 3-7B model) executes sequentially
- [ ] Complex task pool (1x 7B coder) with orchestrator swap
- [ ] LangGraph decompose graph implemented
- [ ] MCP filesystem tool server working

### Phase 3: Self-Debugging (Weeks 5-6) ğŸ”§
- [ ] Code runner tool server implemented
- [ ] Pytest execution and parsing works
- [ ] LangGraph debug loop graph implemented
- [ ] Reflection loop: fail â†’ analyze â†’ fix â†’ retry
- [ ] AST parsing for syntax validation
- [ ] Test coverage for generated code

### Phase 4: n8n Integration (Weeks 7-8) âš™ï¸
- [ ] n8n development environment set up
- [ ] ATOSAgentRouter custom node created
- [ ] Task routing workflow implemented
- [ ] ATOSResultAggregator node created
- [ ] Webhook communication working
- [ ] Error handling in n8n workflows

### Phase 5: Operations (Weeks 9-10) ğŸš€
- [ ] ATOSDeploy node for Heroku
- [ ] GitHub integration (push code)
- [ ] Workflow trigger tool server
- [ ] End-to-end: goal â†’ code â†’ deploy
- [ ] Deployment verification workflow

### Phase 6: Observability (Weeks 11-12) ğŸ“Š
- [ ] LangSmith tracing integrated
- [ ] W&B logging for metrics
- [ ] CLI interface (`atos build "goal"`)
- [ ] Status monitoring (`atos status`)
- [ ] Debug commands (`atos debug <task_id>`)

### Phase 7: Polish & Documentation (Week 13+) âœ¨
- [ ] Error messages improved
- [ ] User documentation written
- [ ] Example projects created
- [ ] Performance optimization
- [ ] Demo video recorded

---

## ğŸ¯ Current Status

**Phase:** Foundation (Week 1)  
**Last Updated:** [Your Date]  
**Current Focus:** Setting up repository structure and pulling models

**Next Milestones:**
1. Get Ollama working with one model
2. Write tracer bullet #1 (single model call)
3. Implement basic AgentPoolManager

**Blockers:**
- [ ] None yet (hopefully!)

*(Update this section as you progress)*

---

## ğŸ§ª Testing Strategy

### Unit Tests
```bash
pytest tests/unit/ -v
```
Test individual components in isolation (agent manager, orchestrator, tools).

### Integration Tests
```bash
pytest tests/integration/ -v
```
Test multi-component workflows (agent pool + n8n, orchestrator + tools).

### End-to-End Tests
```bash
python examples/04_full_orchestration.py
```
Full user journey: goal â†’ decomposed â†’ executed â†’ deployed.

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| **Orchestrator** | Qwen2.5:7B | Best 7B reasoning model, 128K context |
| **Coders** | Qwen2.5-Coder:7B/3B | Top code generation models |
| **Simple Agents** | Phi-3.5:3.8B, Gemma2:2B | Lightweight, specialized |
| **Agent Framework** | LangGraph | State machines for reasoning loops |
| **Tool Protocol** | MCP (via FastAPI) | Standardized agent-tool interface |
| **Orchestration** | n8n (self-hosted) | Workflow automation + custom nodes |
| **Observability** | LangSmith + W&B | LLM tracing + metrics |
| **Testing** | pytest | Code validation in debug loops |
| **Language** | Python 3.10+ | Main application |
| **Custom Nodes** | TypeScript | n8n node development |

---

## ğŸ’¾ Resource Requirements

**Minimum Specs:**
- GPU: 4GB VRAM (RTX 3050, GTX 1650)
- RAM: 16GB
- Storage: 50GB
- CPU: 6+ cores

**Recommended Specs:**
- GPU: 6-8GB VRAM (RTX 3060)
- RAM: 32GB
- Storage: 100GB SSD
- CPU: 8+ cores

---

## ğŸ› Common Issues & Solutions

### Model Loading Fails
```bash
# Check Ollama is running
curl http://localhost:11434/api/tags

# Verify model is pulled
ollama list

# Check VRAM usage
nvidia-smi
```

### VRAM Overflow
```bash
# Monitor in real-time
watch -n 1 nvidia-smi

# Force unload all models
python scripts/cleanup.sh
```

### n8n Won't Start
```bash
# Check port availability
lsof -i :5678

# Restart n8n
pkill -f n8n
npx n8n start
```

See `docs/troubleshooting.md` for full list.

---

## ğŸ“š Learning Resources

**Before you code, read:**
- [Ollama Python Docs](https://github.com/ollama/ollama-python)
- [LangGraph Tutorial](https://langchain-ai.github.io/langgraph/tutorials/)
- [FastAPI Docs](https://fastapi.tiangolo.com/)
- [n8n Node Creation](https://docs.n8n.io/integrations/creating-nodes/)

**Concepts to understand:**
- Async/await in Python
- State machines (LangGraph)
- Dependency injection (FastAPI)
- TypeScript classes (n8n nodes)
- VRAM vs RAM

---

## ğŸ“ Development Philosophy

This project follows **"Learn by Building Hard Things"**:

1. **No spoon-feeding** - Figure it out, break it, fix it
2. **Documentation first** - Read docs before asking
3. **Test in isolation** - REPL is your friend
4. **Commit often** - So you can revert when you fuck up
5. **Debug systematically** - Print everything, read errors
6. **Embrace struggle** - Confusion means you're learning

**Mantra:** "If it's easy, I'm not learning."

---

## ğŸ¤ Contributing

This is a personal learning project, but feedback welcome!

**If you want to learn alongside:**
1. Fork this repo
2. Follow the build phases
3. Share your struggles (and solutions!) in Issues
4. Document your unique insights

**What NOT to do:**
- Don't submit "just use X library" PRs (defeats the learning purpose)
- Don't refactor for "cleanliness" (clarity > elegance when learning)

---

## ğŸ“ Build Log

Keep a daily journal in `docs/build_log.md`:

```markdown
## Day 1 - [Date]
**Goal:** Set up repository structure  
**What I learned:** How to organize a multi-language monorepo  
**Blockers:** None  
**Tomorrow:** Pull Ollama models and test first model call

## Day 2 - [Date]
**Goal:** Get Qwen2.5:7B running  
**What I learned:** Q4_K_M quantization reduces VRAM by 75%  
**Blockers:** Model loading takes 8 seconds (normal?)  
**Tomorrow:** Write tracer bullet script
```

This is YOUR learning log. Be honest about struggles.

---

## ğŸ”® Future Extensions

After completing the base project:

1. **Polymathic Engine Integration** - Add knowledge graph for innovation
2. **Multi-GPU Support** - Scale to larger models
3. **Web UI** - React dashboard for monitoring
4. **Cloud Deployment** - Run orchestrator on server, agents on edge
5. **Fine-tuned Agents** - Train specialized micro-models

---

## ğŸ“„ License

MIT License - See `LICENSE` file

---

## ğŸ™ Acknowledgments

**Built on the shoulders of:**
- Ollama team (local LLM runtime)
- Qwen team (amazing open models)
- LangChain/LangGraph (agent frameworks)
- n8n team (workflow automation)

**Inspired by:**
- The idea that $0 and consumer hardware can run production-grade AI systems
- The belief that struggling through hard projects is the best teacher

---

## ğŸ“§ Contact

**Questions about the project?** Open an issue.  
**Want to share your learning?** Post in Discussions.  
**Found a bug?** You probably caused it. Debug it. Then tell me how. ğŸ˜‰

---

**Remember:** This README is your north star. When lost, come back here. When stuck, read the relevant section. When you want to give up, remember why you started.

**You're not building a calculator. You're building a distributed AI system. It's supposed to be hard.**

Now go write some code. ğŸš€
